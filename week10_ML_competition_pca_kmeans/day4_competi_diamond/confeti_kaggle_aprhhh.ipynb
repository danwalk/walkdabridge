{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](competi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aquí encontrarás todo lo que necesitas saber: https://www.kaggle.com/t/ab8726f0cfc84544abbae69a6be88071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para que funcione necesitas bajarte los archivos de datos de Kaggle \n",
    "df = pd.read_csv(\"diamonds_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimator(estimator, df_test):\n",
    "    \"\"\"Score an estimator on the test set.\"\"\"\n",
    "    y_pred = estimator.predict(df_test)\n",
    "\n",
    "    print(\"MSE: %.3f\" %\n",
    "          mean_squared_error(df_test[\"price\"], y_pred,\n",
    "                             sample_weight=None))\n",
    "    print(\"MAE: %.3f\" %\n",
    "          mean_absolute_error(df_test[\"price\"], y_pred,\n",
    "                              sample_weight=None))\n",
    "\n",
    "    mask = y_pred > 0\n",
    "    if (~mask).any():\n",
    "        n_masked, n_samples = (~mask).sum(), mask.shape[0]\n",
    "        print(f\"WARNING: Estimator yields invalid, non-positive predictions \"\n",
    "              f\" for {n_masked} samples out of {n_samples}. These predictions \"\n",
    "              f\"are ignored when computing the Poisson deviance.\")\n",
    "\n",
    "    print(\"mean Poisson deviance: %.3f\" %\n",
    "          mean_poisson_deviance(df_test[\"price\"][mask],\n",
    "                                y_pred[mask],\n",
    "                                sample_weight=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb_make = LabelEncoder()\n",
    "#df['cut'] = lb_make.fit_transform(df['cut'])\n",
    "#df['color'] = lb_make.fit_transform(df['color'])\n",
    "#df['clarity'] = lb_make.fit_transform(df['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoder = OneHotEncoder(sparse=False, handle_unknown=\"error\", drop=\"first\")\n",
    "#ohe = pd.DataFrame(onehotencoder.fit_transform(df[[\"color\"]]))\n",
    "#df = df.join(ohe)\n",
    "#df.rename(columns={0: \"a\", 1: \"b\", 2: \"c\", 3: \"d\", 4: \"e\", 5: \"f\"}, inplace=True)\n",
    "#oht = pd.DataFrame(onehotencoder.fit_transform(df[[\"clarity\"]]))\n",
    "#df = df.join(oht)\n",
    "#df.rename(columns={0: \"g\", 1: \"h\", 2: \"i\", 3: \"j\", 4: \"k\", 5: \"m\", 6: \"o\", 7: \"o\", 8: \"p\"}, inplace=True)\n",
    "#df[\"carat\"] = df[\"carat\"]*100\n",
    "#df[\"price\"] = df[\"price\"]/100\n",
    "#df[\"x\"] = df[\"x\"]*9\n",
    "#df[\"y\"] = df[\"y\"]*9\n",
    "#df[\"z\"] = df[\"z\"]*9\n",
    "df[\"x\"] = df[\"x\"] + df[\"y\"] + df[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(df[[\"carat\", \"cut\",  \"color\", \"clarity\", \"depth\",  \"table\", \"x\", \"y\", \"z\"]]) #without cut, depth\n",
    "#y = np.array(df[\"price\"])\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z  price\n",
       "0   1.21      Ideal     H     VS2   63.0   57.0  6.73  6.70  4.23   6134\n",
       "1   0.28  Very Good     D    VVS2   64.0   56.0  4.14  4.17  2.66    532\n",
       "2   0.42    Premium     F     VS1   61.2   58.0  4.86  4.82  2.96   1103\n",
       "3   0.26      Ideal     H      IF   61.1   57.0  4.16  4.12  2.53    600\n",
       "4   1.10       Good     G     SI1   63.4   57.0  6.52  6.55  4.14   4997"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.21</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>63.0</td>\n      <td>57.0</td>\n      <td>6.73</td>\n      <td>6.70</td>\n      <td>4.23</td>\n      <td>6134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.28</td>\n      <td>Very Good</td>\n      <td>D</td>\n      <td>VVS2</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>4.14</td>\n      <td>4.17</td>\n      <td>2.66</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>Premium</td>\n      <td>F</td>\n      <td>VS1</td>\n      <td>61.2</td>\n      <td>58.0</td>\n      <td>4.86</td>\n      <td>4.82</td>\n      <td>2.96</td>\n      <td>1103</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>IF</td>\n      <td>61.1</td>\n      <td>57.0</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>2.53</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.10</td>\n      <td>Good</td>\n      <td>G</td>\n      <td>SI1</td>\n      <td>63.4</td>\n      <td>57.0</td>\n      <td>6.52</td>\n      <td>6.55</td>\n      <td>4.14</td>\n      <td>4997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['carat'] = (df['carat'] - df['carat'].mean()) / df['carat'].std()\n",
    "#df['x'] = (df['x'] - df['x'].mean()) / df['x'].std()\n",
    "#df['y'] = (df['y'] - df['y'].mean()) / df['y'].std()\n",
    "#df['z'] = (df['z'] - df['z'].mean()) / df['z'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['carat'] = df['carat']*10\n",
    "#X = df[[\"carat\", \"x\", \"y\", \"z\"]]\n",
    "#y = df[[\"price\"]]\n",
    "#train_data = X_train\n",
    "#train_label = y_train\n",
    "#test_dataX = X_test\n",
    "#test_datay = y_test\n",
    "\n",
    "\n",
    "#train_pool = Pool(train_data, \n",
    "                  #train_label,\n",
    "                  #)\n",
    "#test_pool = Pool(test_dataX,\n",
    "                 #test_datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[[\"carat\", \"x\", \"y\", \"z\"]]\n",
    "#y = df[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = X_train\n",
    "#train_label = y_train\n",
    "#test_dataX = X_test\n",
    "#test_datay = y_test\n",
    "\n",
    "\n",
    "#train_pool = Pool(train_data, \n",
    "                  train_label,\n",
    "                  )\n",
    "#test_pool = Pool(test_dataX,\n",
    "                 test_datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = CatBoostRegressor(learning_rate=0.05, depth=6, l2_leaf_reg=1, iterations=150)\n",
    "\n",
    "#grid = {'learning_rate': [0.05],\n",
    "        'depth': [6],\n",
    "        'l2_leaf_reg': [1]}\n",
    "\n",
    "#grid_search_result = model2.grid_search(grid, \n",
    "                                       #X, \n",
    "                                       #y, \n",
    "                                      # plot=True) #cat_features=[1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Poisson Gradient Boosted Trees evaluation:\n",
      "MSE: 102529.445\n",
      "MAE: 143.551\n",
      "mean Poisson deviance: 12.578\n"
     ]
    }
   ],
   "source": [
    "tree_preprocessor = ColumnTransformer(\r\n",
    "    [\r\n",
    "        (\"categorical\", OrdinalEncoder(),\r\n",
    "            [\"cut\", \"color\", \"clarity\"]),\r\n",
    "        (\"numeric\", \"passthrough\",\r\n",
    "            [\"carat\", \"x\", \"y\", \"z\"]),\r\n",
    "    ],\r\n",
    "    remainder=\"drop\",\r\n",
    ")\r\n",
    "poisson_gbrt = Pipeline([\r\n",
    "    (\"preprocessor\", tree_preprocessor),\r\n",
    "    (\"regressor\", HistGradientBoostingRegressor(loss=\"poisson\",                           #Aqui se puede poner diferentes regressors\r\n",
    "                                                max_leaf_nodes=128)),\r\n",
    "])\r\n",
    "poisson_gbrt.fit(df_train, df_train[\"price\"],\r\n",
    "                 regressor__sample_weight=None)\r\n",
    "\r\n",
    "print(\"Poisson Gradient Boosted Trees evaluation:\")\r\n",
    "score_estimator(poisson_gbrt, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg1 = GradientBoostingRegressor(random_state=1)\n",
    "#reg2 = RandomForestRegressor(random_state=1)\n",
    "#reg3 = LinearRegression()\n",
    "#ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = poisson_gbrt.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "102529.44520299621"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "mean_squared_error(df['price'], h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = poisson_gbrt.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 6210.89666667,   558.41      ,  1105.66      , ...,\n",
       "        1299.76      , 10302.06      ,  1187.627     ])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"price\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       carat        cut color clarity  depth  table     x     y     z  price\n",
       "0       1.21      Ideal     H     VS2   63.0   57.0  6.73  6.70  4.23      0\n",
       "1       0.28  Very Good     D    VVS2   64.0   56.0  4.14  4.17  2.66      0\n",
       "2       0.42    Premium     F     VS1   61.2   58.0  4.86  4.82  2.96      0\n",
       "3       0.26      Ideal     H      IF   61.1   57.0  4.16  4.12  2.53      0\n",
       "4       1.10       Good     G     SI1   63.4   57.0  6.52  6.55  4.14      0\n",
       "...      ...        ...   ...     ...    ...    ...   ...   ...   ...    ...\n",
       "40340   1.55    Premium     H     VS2   61.3   61.0  7.46  7.39  4.55      0\n",
       "40341   0.36      Ideal     D     SI1   60.6   56.0  4.58  4.63  2.79      0\n",
       "40342   0.57  Very Good     I     VS2   62.2   55.0  5.33  5.34  3.32      0\n",
       "40343   1.01  Very Good     F      IF   59.6   62.0  6.47  6.56  3.88      0\n",
       "40344   0.54      Ideal     E     SI2   60.4   57.0  5.33  5.27  3.20      0\n",
       "\n",
       "[40345 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.21</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>63.0</td>\n      <td>57.0</td>\n      <td>6.73</td>\n      <td>6.70</td>\n      <td>4.23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.28</td>\n      <td>Very Good</td>\n      <td>D</td>\n      <td>VVS2</td>\n      <td>64.0</td>\n      <td>56.0</td>\n      <td>4.14</td>\n      <td>4.17</td>\n      <td>2.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.42</td>\n      <td>Premium</td>\n      <td>F</td>\n      <td>VS1</td>\n      <td>61.2</td>\n      <td>58.0</td>\n      <td>4.86</td>\n      <td>4.82</td>\n      <td>2.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>IF</td>\n      <td>61.1</td>\n      <td>57.0</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>2.53</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.10</td>\n      <td>Good</td>\n      <td>G</td>\n      <td>SI1</td>\n      <td>63.4</td>\n      <td>57.0</td>\n      <td>6.52</td>\n      <td>6.55</td>\n      <td>4.14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40340</th>\n      <td>1.55</td>\n      <td>Premium</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>61.3</td>\n      <td>61.0</td>\n      <td>7.46</td>\n      <td>7.39</td>\n      <td>4.55</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40341</th>\n      <td>0.36</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>SI1</td>\n      <td>60.6</td>\n      <td>56.0</td>\n      <td>4.58</td>\n      <td>4.63</td>\n      <td>2.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40342</th>\n      <td>0.57</td>\n      <td>Very Good</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.2</td>\n      <td>55.0</td>\n      <td>5.33</td>\n      <td>5.34</td>\n      <td>3.32</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40343</th>\n      <td>1.01</td>\n      <td>Very Good</td>\n      <td>F</td>\n      <td>IF</td>\n      <td>59.6</td>\n      <td>62.0</td>\n      <td>6.47</td>\n      <td>6.56</td>\n      <td>3.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40344</th>\n      <td>0.54</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>60.4</td>\n      <td>57.0</td>\n      <td>5.33</td>\n      <td>5.27</td>\n      <td>3.20</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40345 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = poisson_gbrt.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40345,)"
      ]
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 6259.42 ,   571.3  ,  1099.4  , ...,  1300.94 , 10281.635,\n",
       "        1225.27 ])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante:**\n",
    "\n",
    "   - Si quitas columnas o creas columnas nuevas a partir de otras, o cualquier modificación column-wise tendrás que aplicarlo al dataset de `titanic_test.csv` de cara a hacer la predicción.\n",
    "   - Si por lo contrario, decides por ejemplo, quitar los outliers o hacer un `dropna()`, o cualquier modificación row-wise eso NO PODRÁS (ni debes) aplicarlo al dataset de `titanic_test.csv` de cara a hacer la predicción. ¿Por qué? Porque si el conjunto de test tiene 50 observaciones (filas) la predicción se espera que tenga 50 filas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Y si lo que hago es estandarizar los datos o hacer un encoding, también se lo tengo que hacer al test antes de predecir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿qué opináis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos que si o si debéis realizar para poder participar en la competición:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definir X e y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Y si después del análisis exploratorio de mis datos llego a la conclusión de que puedo predecir el precio solo con las columnas `x`, `y` y `z`, también aplica al test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿qué opináis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dividir X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Asignar el modelo (vacío) a una variable\n",
    "Aquí meteríais los parámetros. \n",
    "\n",
    "**Consejo**: Usa GridSearch y vuélvete loca o loco probando modelos e hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre hay tiempo para una historia:\n",
    "https://catboost.ai/docs/concepts/python-reference_catboostregressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenar el modelo con X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predecir con el modelo ya entrenado con X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 6210.89666667   558.41        1105.66       ...  1299.76\n 10302.06        1187.627     ]\n"
     ]
    }
   ],
   "source": [
    "predictions = poisson_gbrt.predict(df)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Sacar métricas, valorar el modelo \n",
    "\n",
    "Recuerdo que en la competición se va a evaluar con la métrica de RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una vez listo el modelo, toca predecir con el dataset de predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de **modelo que está listo**. \n",
    "\n",
    "_Tras hacer suficientes pruebas, analizar los datos, hacer feature engineering, probar diferentes modelos con diferentes parámetros, es con este con el que observo mejores métricas y menos overfitting. ¡Cuidado con el overfitting aquí! Si vuestro modelo aprende muy bien de estos datos pero hay overfitting cuando le pasemos los datos desconocidos de `diamonds_test.csv` nos arriesgamos a que digamos, no salga lo esperado._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Entrena dicho modelo con TODOS tus datos de train, esto es con `diamonds_train.csv` al completo.\n",
    "\n",
    "**CON LAS TRANSFORMACIONES QUE LE HAYAS REALIZADO A `X` INCLUÍDAS.**\n",
    "\n",
    "Véase:\n",
    "- Estandarización/Normalización\n",
    "- Eliminación de Outliers\n",
    "- Eliminación de columnas\n",
    "- Creación de columnas nuevas\n",
    "- Gestión de valores nulos\n",
    "- Y un largo etcétera de técnicas que como Data Scientist hayas considerado las mejores para tu dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga los datos de `diamonds_test.csv` para predecir.\n",
    "\n",
    "**¿De dónde saco `diamonds_test.csv`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z\n",
       "0   0.30      Ideal     H     SI2   60.0   56.0  4.41  4.43  2.65\n",
       "1   0.34      Ideal     D      IF   62.1   57.0  4.52  4.46  2.79\n",
       "2   1.57  Very Good     I     VS2   60.3   58.0  7.58  7.55  4.56\n",
       "3   0.31      Ideal     H     VS2   61.8   57.0  4.32  4.36  2.68\n",
       "4   1.51       Good     I    VVS1   64.0   60.0  7.26  7.21  4.63"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.30</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>SI2</td>\n      <td>60.0</td>\n      <td>56.0</td>\n      <td>4.41</td>\n      <td>4.43</td>\n      <td>2.65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.34</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>IF</td>\n      <td>62.1</td>\n      <td>57.0</td>\n      <td>4.52</td>\n      <td>4.46</td>\n      <td>2.79</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.57</td>\n      <td>Very Good</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>60.3</td>\n      <td>58.0</td>\n      <td>7.58</td>\n      <td>7.55</td>\n      <td>4.56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.31</td>\n      <td>Ideal</td>\n      <td>H</td>\n      <td>VS2</td>\n      <td>61.8</td>\n      <td>57.0</td>\n      <td>4.32</td>\n      <td>4.36</td>\n      <td>2.68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.51</td>\n      <td>Good</td>\n      <td>I</td>\n      <td>VVS1</td>\n      <td>64.0</td>\n      <td>60.0</td>\n      <td>7.26</td>\n      <td>7.21</td>\n      <td>4.63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "X_pred = pd.read_csv(\"diamonds_test.csv\", index_col=0)\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred[\"price\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13449, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Por qué da error?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  419.55,  1777.  ,  9852.21, ..., 15438.9 , 10677.24,   720.99])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "predictions_submit = poisson_gbrt.predict(X_pred)\n",
    "predictions_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANTE: APLICAR LO MISMO A ESTOS DATOS QUE HAYÁIS APLICADO A LOS DATOS DE ENTRENAMIENTO\n",
    "\n",
    "- SI EL ARRAY CON EL QUE HICISTEIS `.fit()` ERA DE 4 COLUMNAS, PARA `.predict()` DEBEN SER LAS MISMAS\n",
    "- SI AL ARRAY CON EL QUE HICISTEIS `.fit()` LO NORMALIZASTEIS, PARA `.predict()` DEBÉIS NORMALIZARLO\n",
    "- TODO IGUAL SALVO BORRAR FILAS, EL NÚMERO DE ROWS SE DEBE MANTENER EN ESTE SET, PUES LA PREDICCIÓN DEBE TENER 13449 FILAS, SI O SI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entonces, si al cargar los datos de train usé `index_col=0` para que utilizara la primera columna del conjunto de datos como índice, ¿tendré que hacerlo también para el conjunto `diamonds_test.csv`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué opináis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tierraljelechu.com/web/img/wiki_up/1.996-SorpresaDto.-1-Red.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué más habrá que quitar o hacer?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué opináis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tierraljelechu.com/web/img/wiki_up/1.996-SorpresaDto.-1-Red.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Truqui**: Carga X que debe estar actualmente actualizada a cómo la usaste para entrenar a `model` y haz que `to_pred` sea igual. ¡Sin quitar filas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque:\n",
    "    - SI EL ARRAY CON EL QUE HICISTEIS `.fit()` ERA DE 3 COLUMNAS, PARA `.predict()` DEBEN SER LAS MISMAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. AHORA puedo hacer la predicción que será lo que subirás a Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué es lo que subirás a Kaggle?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡PERO! Para subir a Kaggle la predicción, ésta tendrá que tener una forma específica y no valdrá otra.**\n",
    "\n",
    "En este caso, la **MISMA** forma que `sample_submission.csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿De dónde saco `diamonds_test.csv`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  price\n",
       "0   0  12132\n",
       "1   1  11786\n",
       "2   2  14684\n",
       "3   3  15425\n",
       "4   4   6724"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>12132</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14684</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15425</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6724</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13449, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mete tus predicciones en un dataframe. \n",
    "\n",
    "En este caso, la **MISMA** forma que `sample_submission.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": range(len(predictions_submit)), \"price\": predictions_submit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id        price\n",
       "0   0   419.550000\n",
       "1   1  1777.000000\n",
       "2   2  9852.210000\n",
       "3   3   510.227238\n",
       "4   4  8507.760000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>419.550000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1777.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>9852.210000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>510.227238</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8507.760000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13449, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pásale el CHEQUEATOR para comprobar que efectivamente está listo para subir a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                submission.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chequeator in module __main__:\n",
      "\n",
      "chequeator(df_to_submit)\n",
      "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
      "    \n",
      "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
      "    \n",
      "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
      "    \n",
      "    Si aún no:\n",
      "    - apaga tu ordenador, \n",
      "    - date una vuelta, \n",
      "    - enciendelo otra vez, \n",
      "    - abre este notebook y \n",
      "    - leelo todo de nuevo. \n",
      "    Todos nos merecemos una segunda oportunidad. También tú.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(chequeator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "interpreter": {
   "hash": "16eb897c26cdfcf18817bc60a8e0737e3939ff1e8491198c807979170104e811"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}